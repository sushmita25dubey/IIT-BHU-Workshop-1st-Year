{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushmita25dubey/IIT-BHU-Workshop-1st-Year/blob/main/Session_4_(DAY%201%20).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ¤— Hugging Face Workshop\n",
        "\n",
        "![](https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo-with-title.png)"
      ],
      "metadata": {
        "id": "p1pRCYwfYpy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Introduction to Hugging Face**"
      ],
      "metadata": {
        "id": "Zwk_uCarYsuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Hugging Face?\n",
        "Hugging Face is an open-source platform specializing in Natural Language Processing (NLP) and Machine Learning (ML). It provides pre-trained models for tasks like text generation, translation, summarization, and more. With Hugging Face, you can:\n",
        "- Use pre-trained models from the Transformers library.\n",
        "- Fine-tune models on your own dataset.\n",
        "- Share and discover models via the Hugging Face Hub.\n",
        "\n",
        "Hugging Face is a powerful tool for both beginners and experts in AI/ML!"
      ],
      "metadata": {
        "id": "Ma4U_ufjYuJy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Setting up the environment**"
      ],
      "metadata": {
        "id": "hmZTK_dvY-5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understand & install the libraries\n",
        "\n",
        "Before we install the libraries, let's understand their purpose:\n",
        "\n",
        "- **Transformers:** Provides pre-trained models and tools to fine-tune or deploy them for NLP tasks like text classification, translation, and summarization.\n",
        "- **Datasets:** Simplifies downloading and preparing large datasets, particularly those commonly used in NLP tasks.\n",
        "- **Accelerate:** Optimizes model training, enabling faster computation and support for distributed training setups.\n",
        "- **Huggingface-hub:** Provides tools to interact with the Hugging Face Hub, allowing users to download, upload, and manage models and datasets."
      ],
      "metadata": {
        "id": "hRCw6jQNchC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Hugging Face Transformers library\n",
        "!pip install transformers datasets --quiet\n",
        "\n",
        "# Optional: Install Accelerate for faster training\n",
        "!pip install accelerate --quiet\n",
        "\n",
        "# Install Hugging Face Hub\n",
        "!pip install huggingface-hub --quiet"
      ],
      "metadata": {
        "id": "SfsTyGtgktan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Getting Your Hugging Face Token**\n",
        "\n",
        "### Why Do You Need a Token?\n",
        "To access private models or push your own models to the Hugging Face Hub, you need an authentication token.\n",
        "\n",
        "### Steps to Get Your Token:\n",
        "1. Go to the [Hugging Face website](https://huggingface.co/).\n",
        "2. Create an account or log in.\n",
        "3. Click on your profile picture in the top right corner.\n",
        "4. Select **Access Tokens**.\n",
        "5. Click **New Token** and create a token with the required permissions.\n",
        "6. Copy the token to your clipboard."
      ],
      "metadata": {
        "id": "YRQMrkDlZR0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Logging into Hugging Face in Google Colab**\n",
        "\n",
        "Run the following code cell and paste your token when prompted:"
      ],
      "metadata": {
        "id": "G1aZ6imdZYKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "# Log in to Hugging Face\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "KInBvBW0ZQo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Using Hugging Face Transformers**"
      ],
      "metadata": {
        "id": "mtRr-C4KZoqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Using Pipelines\n",
        "\n",
        "Pipelines make it easy to use pre-trained models for common tasks by abstracting the complexities of model loading, tokenization, and inference. Hereâ€™s how they work:\n",
        "\n",
        "1. **Model Selection:** The pipeline function automatically selects a suitable pre-trained model for the specified task (e.g., summarization, sentiment analysis, translation).\n",
        "2. **Data Preparation:** It processes the input text (e.g., tokenizing it) to make it compatible with the model's requirements.\n",
        "3. **Inference Execution:** The pipeline runs the input through the model to generate predictions or outputs.\n",
        "4. **Output Formatting:** It converts raw model outputs (like tensors) into a user-friendly format (like plain text or structured data).\n",
        "\n",
        "Pipelines eliminate the need for manual setup, such as loading models, tokenizers, and writing preprocessing or postprocessing code. This makes them ideal for beginners exploring NLP tasks and for quick prototyping.\n",
        "\n",
        "---\n",
        "\n",
        "For more details, check out these resources:\n",
        "- [Hugging Face Documentation on Pipelines](https://huggingface.co/docs/transformers/main_classes/pipelines)\n",
        "- [Video: \"The pipeline function\"](https://www.youtube.com/watch?v=tiZFewofSLM)\n",
        "\n",
        "---\n",
        "\n",
        "Here's are various types of pipelines:"
      ],
      "metadata": {
        "id": "ZAHzv3H3Zt7k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Summarization Pipeline\n",
        "\n",
        "This is used for generating a summary of a given text."
      ],
      "metadata": {
        "id": "130Z_Q8BuMqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "XjsNS7v-ZfxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize some text\n",
        "text = \"\"\"\n",
        "Artificial Intelligence (AI) is a field of computer science that emphasizes the creation of intelligent machines\n",
        "that work and react like humans. Some of the activities computers with AI are designed for include learning, reasoning,\n",
        "problem-solving, perception, and language understanding. The ultimate goal of AI is to create systems that can function\n",
        "intelligently and independently.\n",
        "\"\"\"\n",
        "\n",
        "summary = summarizer(text, max_length=50, min_length=25, do_sample=False)\n",
        "print(\"\\nSummary:\\n\")\n",
        "print(summary[0]['summary_text'])"
      ],
      "metadata": {
        "id": "4kjmd0teaGSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Sentiment Analysis Pipeline\n",
        "\n",
        "This pipeline is used to analyze the sentiment (positive, negative, or neutral) of a given text."
      ],
      "metadata": {
        "id": "RjoYCgBYuYhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a sentiment analysis pipeline with a specific model\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")"
      ],
      "metadata": {
        "id": "JxOq4afsu3MH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze sentiment of some text\n",
        "text = \"I love this new phone! It's so fast and has a great camera.\"\n",
        "\n",
        "sentiment = sentiment_analyzer(text)\n",
        "print(\"\\nSentiment Analysis:\\n\")\n",
        "print(sentiment)"
      ],
      "metadata": {
        "id": "zlmzypTsu4V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Text Classification Pipeline\n",
        "\n",
        "This pipeline is used for classifying text into predefined categories (e.g., spam detection, topic classification)."
      ],
      "metadata": {
        "id": "ZYg1FdDbuk83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a text classification pipeline with a specific model\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "id": "FA12siESu7Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classify text into labels\n",
        "text = \"I am learning Python programming and NLP.\"\n",
        "\n",
        "labels = [\"Technology\", \"Science\", \"Education\"]\n",
        "classification = classifier(text, candidate_labels=labels)\n",
        "print(\"\\nText Classification:\\n\")\n",
        "print(classification)"
      ],
      "metadata": {
        "id": "c5zNwbO5u7Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Translation Pipeline\n",
        "\n",
        "This pipeline is used for translating text from one language to another."
      ],
      "metadata": {
        "id": "hu4BCAkSun5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a translation pipeline with a specific model\n",
        "translator = pipeline(\"translation_en_to_fr\", model=\"t5-small\")"
      ],
      "metadata": {
        "id": "GXrmq8Dgu9-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translate some text\n",
        "text = \"Hello, how are you today?\"\n",
        "\n",
        "translation = translator(text)\n",
        "print(\"\\nTranslation (English to French):\\n\")\n",
        "print(translation[0]['translation_text'])"
      ],
      "metadata": {
        "id": "7dYH35k9u90n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Named Entity Recognition (NER) Pipeline\n",
        "\n",
        "This pipeline is used to identify and classify entities (like names, locations, dates) in a given text."
      ],
      "metadata": {
        "id": "Rlu-oHzruroX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a NER pipeline with a specific model\n",
        "ner_tagger = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")"
      ],
      "metadata": {
        "id": "ucrNZvjIvA7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recognize entities in the text\n",
        "text = \"Elon Musk, the CEO of Tesla, visited Paris in 2023.\"\n",
        "\n",
        "entities = ner_tagger(text)\n",
        "print(\"\\nNamed Entity Recognition:\\n\")\n",
        "for entity in entities:\n",
        "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}\")"
      ],
      "metadata": {
        "id": "7aM4GfVKvA5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Question Answering Pipeline\n",
        "This pipeline is used to answer questions based on a provided context."
      ],
      "metadata": {
        "id": "IR5m-4Bmuuam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a question answering pipeline with a specific model\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")"
      ],
      "metadata": {
        "id": "oeaGR1Z-vEHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Context and question\n",
        "context = \"\"\"\n",
        "Hugging Face is a company that develops machine learning tools and offers an open-source platform for training,\n",
        "deploying, and sharing machine learning models. It was founded in 2016 by ClÃ©ment Delangue, Julien Chaumond, and Thomas Wolf.\n",
        "\"\"\"\n",
        "question = \"Who founded Hugging Face?\"\n",
        "\n",
        "# Answer the question based on context\n",
        "answer = qa_pipeline(question=question, context=context)\n",
        "print(\"\\nQuestion Answering:\\n\")\n",
        "print(f\"Answer: {answer['answer']}\")"
      ],
      "metadata": {
        "id": "fJ_sfyhrvEEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Custom Tokenization and Model Usage\n",
        "\n",
        "Custom tokenization and model usage provide greater control over the NLP pipeline, making it suitable for advanced use cases where specific model configurations or inputs are required. Unlike pipelines, this method lets you directly manage each component, giving flexibility for fine-tuning, custom preprocessing, and interpreting intermediate outputs.\n",
        "\n",
        "Use cases for custom tokenization include:\n",
        "- **Custom preprocessing:** When your data requires specific cleaning or formatting steps before tokenization.\n",
        "- **Model-specific adjustments:** To modify parameters or inputs for a particular task or dataset.\n",
        "- **Debugging or analysis:** To inspect intermediate outputs like tokenized inputs or logits for better interpretability.\n",
        "\n",
        "---\n",
        "\n",
        "Here's an example of how to manually tokenize and use a pre-trained model:"
      ],
      "metadata": {
        "id": "rzF9SnNGZ2xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Define model and tokenizer\n",
        "model_name = \"Falconsai/text_summarization\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "-Ec1IreNZx-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text\n",
        "text = \"\"\"\n",
        "Computer programming or coding is the composition of sequences of instructions, called programs, that computers can follow to perform tasks.\n",
        "It involves designing and implementing algorithms, step-by-step specifications of procedures, by writing code in one or more programming languages.\n",
        "Programmers typically use high-level programming languages that are more easily intelligible to humans than machine code, which is directly\n",
        "executed by the central processing unit. Proficient programming usually requires expertise in several different subjects, including knowledge of the\n",
        "application domain, details of programming languages and generic code libraries, specialized algorithms, and formal logic.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize input\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Pass inputs through the model\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Get predictions\n",
        "logits = outputs.logits\n",
        "predictions = logits.argmax(dim=-1).item()\n",
        "label_map = {0: \"Negative\", 1: \"Positive\"}\n",
        "print(\"Sentiment:\", label_map[predictions])"
      ],
      "metadata": {
        "id": "FqZHo6iiasqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Explore More**\n",
        "\n",
        "The Hugging Face Hub offers a variety of pre-trained models for tasks like text classification, image generation, and speech recognition. You can search for models using:\n",
        "\n",
        "- **Tags:** Filter models by task, language, or framework.\n",
        "- **Search Bar:** Enter keywords like \"text generation\" or \"sentiment analysis\" to find relevant models.\n",
        "- **Filters:** Refine your search by dataset, license type, or size of the model.\n",
        "\n",
        "Check out the [Hugging Face Hub](https://huggingface.co/models) for more models to try!\n",
        "\n",
        "More resources to try out:\n",
        "1. [Hugging Face's NLP Course](https://huggingface.co/learn/nlp-course/en/chapter2/1)\n",
        "2. [Open Source AI Cookbook](https://huggingface.co/learn/cookbook/index)"
      ],
      "metadata": {
        "id": "-0hNNTOJZ7Yw"
      }
    }
  ]
}